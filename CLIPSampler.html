<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>CLIPsampler Paper</title>
    <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700,200" rel="stylesheet">
    <link href="https://maxcdn.bootstrapcdn.com/font-awesome/latest/css/font-awesome.min.css" rel="stylesheet">
    <link href="css/aos.css?ver=1.1.0" rel="stylesheet">
    <link href="css/bootstrap.min.css?ver=1.1.0" rel="stylesheet">
    <link href="css/main.css?ver=1.1.0" rel="stylesheet">
    <noscript>
      <style type="text/css">
        [data-aos] {
            opacity: 1 !important;
            transform: translate(0) scale(1) !important;
        }
      </style>
    </noscript>
  </head>
  <body id="top">
    <div class="page-content">
      <div>
<div class="profile-page">
  <div class="wrapper">
    <div class="page-header page-header-small" filter-color="green">
      <div class="page-header-image" data-parallax="true" style="background-image: url('images/cc-bg-1.jpg')"></div>
      <div class="container">
        <div class="content-center">
          <div class="cc-profile-image"><a href="/"><img src="images/Parsa Haghighi.jpg" alt="Image"/></a></div>
          <div class="h2 title">Parsa Haghighi</div>
          <a class="btn btn-primary smooth-scroll mr-2" href="/#about" data-aos="zoom-in" data-aos-anchor="data-aos-anchor">Contact Me</a><a class="btn btn-primary" href="https://github.com/parsa178/parsa178.github.io/raw/main/files/Parsa_Haghighi_Naeini_CV.pdf" data-aos="zoom-in" data-aos-anchor="data-aos-anchor">Download CV</a>
        </div>
      </div>
      <div class="section">
        <div class="container">
          <div class="button-container">
            <a class="btn btn-default btn-round btn-lg btn-icon" href="https://scholar.google.com/citations?user=aHBqW7wAAAAJ&hl=en" rel="tooltip">
              <img src="images/google-scholar-white.png" alt="Google Scholar">
            </a>
            <a class="btn btn-default btn-round btn-lg btn-icon" href="https://www.linkedin.com/in/parsa-haghighi-b2156916b/" rel="tooltip"><i class="fa fa-linkedin"></i></a>
            <a class="btn btn-default btn-round btn-lg btn-icon" href="https://github.com/parsa178" rel="tooltip"><i class="fa fa-github"></i></a>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>
</div>
</div>

<style>
  .card-body p,
  .list-group-item {
    font-size: 18px;
  }
</style>

<!-- Empty Space -->
<div style="height: 30px;"></div>

<!-- Block 1: Image -->
<div class="section" id="Pipeline">
  <div class="container" style="max-width: 1400px; ">
    <div style="text-align: center;" class="card" data-aos="fade-up" data-aos-offset="10">
      <div class="row">
        <div style="height: 20px;"></div>
        <div class="h3 mt-0" style="margin: 30px;">CLIPSampler: Distilling CLIP Knowledge to Train a Semantic-Aware Frame Sampler for Efficient Text-Video Retrieval</div>
        <img src="images/Teacher-student Pipeline.jpg" alt="Teacher-student Pipeline" class="img-fluid mx-auto d-block" style="margin: 30px;">
      </div>
    </div>
  </div>
</div>

<div class="section" id="Abstract">
  <div class="container" style="max-width: 1400px;">
    <div style="text-align: center;" class="card" data-aos="fade-up" data-aos-offset="10">
      <div class="row">
        <div class="card-body" style="margin: 35px;">
          <div class="h4 mt-0 title">Abstract</div>
          <p style="text-align: justify;">Application of models specifically designed for images to sampled video frames has become an increasingly popular practice in video understanding. When dealing with lengthy, complex real-world videos, traditional methods often fail because of redundant and irrelevant frames, which highlights the importance of effective frame sampling techniques. In order to address this problem, we introduce a trainable frame sampler tailored for text-to-video retrieval. Our methodology integrates the prowess of the CLIP vision-language model within a teacher-student framework. Our student model, guided by two distinct losses, sharpens its capability to discern frame saliency and grasp the similarities between frames. This approach is motivated by the need for high-speed inference; directly using a query for frame sampling impedes rapid processing due to the recurrent recalculations of video embeddings for each new query. When clustering is performed based on these similarities, a diverse selection is ensured, mitigating visual redundancy, while saliency scores prioritize frames of high semantic significance. To identify the optimal approach for transferring knowledge from CLIP, we explore various losses and student architectures. As another contribution, we propose a set of weakly-supervised videos that can be used as a pre-training dataset for video summarization. This dataset proves effective, even when used in a zero-shot scenario.</p>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="section" id="ContributionsandInnovations">
  <div class="container" style="max-width: 1400px;">
    <div style="text-align: center;" class="card" data-aos="fade-up" data-aos-offset="10">
      <div class="row">
        
          <div class="card-body">
            <div class="h4 mt-0 title">Contributions and Innovations</div>
            <ul class="list-group list-group-flush">
              <li class="list-group-item">Introduction of the first trainable frame sampler for text-to-video retrieval</li>
              <li class="list-group-item">Integration of the CLIP model within a teacher-student framework for a unimodal task</li>
              <li class="list-group-item">Development of an effective and robust approach for clustering frames</li>
              <li class="list-group-item">Creation of a novel weakly-supervised video dataset for pre-training video summarization models</li>
              <li class="list-group-item">Exploration of various loss functions and backbones for improved performance</li>
            </ul>
      </div>
    </div>
    </div>
  </div>
</div>

<div class="section" id="Images">
  <div class="container" style="max-width: 1400px;">
    <div style="text-align: center;" class="card" data-aos="fade-up" data-aos-offset="10">
      <div class="row">
        
          <div class="card-body text-center">
            <div class="h4 mt-0 title">Images</div>
            <div class="card mb-3 mx-auto d-block" style="max-width: 700px; height: 320px;">
              <img src="images/Description-to-Frame Similarity.jpg" alt="Description-to-Frame Similarity" class="img-fluid">
              <div class="card-body">
                <p class="card-text">Calculating the similarity between each frame of a video and its description to determine the importance of each frame.</p>
              </div>
            </div>
            <div class="card mb-3 mx-auto d-block" style="max-width: 700px;  height: 320px;">
              <img src="images/clustering_example.jpg" alt="clustering_example" class="img-fluid" style="max-width: 60%;">
              <div class="card-body">
                <p class="card-text">Performing frame clustering based on robust learned frame-to-frame similarity to select a subset of visually diverse frames</p>
              </div>
            </div>
          </div>
      </div>
    </div>
  </div>
</div>

<div class="section" id="PaperDownload">
  <div class="container"  style="max-width: 1400px;">
    <div style="text-align: center;" class="card" data-aos="fade-up" data-aos-offset="10">
      <div class="row">
        
          <div class="card-body">
            <div class="h4 mt-0 title">Download Paper</div>
            <div style="display: flex; justify-content: center;"> <!-- Center the download icon -->
              <p class="text-center">
                The paper is currently being prepared and will be available soon.<br>
                Please check back later.
              </p> </div>
          </div>
      </div>
    </div>
  </div>
</div>


<footer class="footer">
      <div class="container text-center">
        <a class="cc-google-scholar btn btn-link change-color-on-hover" href="https://scholar.google.com/citations?user=aHBqW7wAAAAJ&hl=en">
          <img src="images/google-scholar-icon.png" alt="Google Scholar" width="30" height="30">
        </a>
        <a class="cc-github btn btn-link" href="https://github.com/parsa178"><i class="fa fa-github fa-2x" aria-hidden="true"></i></a>
        <a class="cc-linkedin btn btn-link" href="https://www.linkedin.com/in/parsa-haghighi-b2156916b/"><i class="fa fa-linkedin fa-2x" aria-hidden="true"></i></a>
      <div class="h4 title text-center">Parsa Haghighi Naeini</div>
      <div class="text-center text-muted">
        <p>&copy; Creative CV. All rights reserved.<br>Design - <a class="credit" href="https://templateflip.com" target="_blank">TemplateFlip</a></p>
      </div>
    </footer>
    <script src="js/core/jquery.3.2.1.min.js?ver=1.1.0"></script>
    <script src="js/core/popper.min.js?ver=1.1.0"></script>
    <script src="js/core/bootstrap.min.js?ver=1.1.0"></script>
    <script src="js/now-ui-kit.js?ver=1.1.0"></script>
    <script src="js/aos.js?ver=1.1.0"></script>
    <script src="scripts/main.js?ver=1.1.0"></script>
  </body>
</html>